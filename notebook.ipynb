{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fore_context(inputs):\n",
    "    return inputs[: inputs.find(\"{end token}\")].replace(\"{start token}\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = '{start token}import numpy as np\\nimport scipy as sp\\n{end token}def hello_world():\\n    print(\"Hello world\"){middle token}'\n",
    "data = {\"inputs\": inputs, \"parameters\": {\"max_new_tokens\": 256}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import numpy as np\\nimport scipy as sp\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_fore_context(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLM:\n",
    "    verbose = False\n",
    "    def __init__(self, conf_file) -> None:\n",
    "        with open(conf_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            conf = yaml.safe_load(f.read())\n",
    "        OPENAI_API_KEY = conf[\"OPENAI_API_KEY\"]\n",
    "        OPENAI_API_BASE = conf[\"OPENAI_API_BASE\"]\n",
    "        OPENAI_API_VERSION = conf[\"OPENAI_API_VERSION\"]\n",
    "        DEPLOYMENT = conf[\"DEPLOYMENT\"]\n",
    "        self.llm = AzureChatOpenAI(\n",
    "            openai_api_type=\"azure\",\n",
    "            openai_api_version=OPENAI_API_VERSION,\n",
    "            openai_api_base=OPENAI_API_BASE,\n",
    "            openai_api_key=OPENAI_API_KEY,\n",
    "            deployment_name=DEPLOYMENT,\n",
    "            temperature=0,\n",
    "        )\n",
    "\n",
    "    def complete(self, query):\n",
    "        \"\"\"Answer to a query.\"\"\"\n",
    "        system_setting = SystemMessage(\n",
    "            content=\"You help to complete the user's code.\")\n",
    "        \n",
    "        message = HumanMessage(content=query)\n",
    "        return self.llm.invoke([system_setting, message]).content\n",
    "    \n",
    "    def complete_code(self, code_context):\n",
    "        \"\"\"Take the input from the request and output.\n",
    "\n",
    "        args:\n",
    "            code_context(str): the code_context\n",
    "\n",
    "        return(dict): the response\n",
    "        \"\"\"\n",
    "        fore_context = get_fore_context(code_context)\n",
    "        system_setting = SystemMessage(\n",
    "            content=\"You are a code autocompleter.\")\n",
    "        prompt = f\"\"\"\n",
    "        Please complete code for the following code. Make code completion after the end token.\n",
    "        \\n\\n\n",
    "        {fore_context}\n",
    "        \"\"\"\n",
    "        message = HumanMessage(content=prompt)\n",
    "        if LLM.verbose:\n",
    "            from pprint import pprint\n",
    "            pprint(prompt)\n",
    "        return self.llm.invoke([system_setting, message]).content\n",
    "\n",
    "llm = LLM(\".env-35-16k.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\n'\n",
      " '        Please complete code for the following code. Make code completion '\n",
      " 'after the end token.\\n'\n",
      " '        \\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '        import numpy as np\\n'\n",
      " 'import scipy as sp\\n'\n",
      " '\\n'\n",
      " '        ')\n",
      "('import matplotlib.pyplot as plt\\n'\n",
      " '\\n'\n",
      " '# Generate some random data\\n'\n",
      " 'x = np.linspace(0, 10, 100)\\n'\n",
      " 'y = np.sin(x)\\n'\n",
      " '\\n'\n",
      " '# Plot the data\\n'\n",
      " 'plt.plot(x, y)\\n'\n",
      " \"plt.xlabel('x')\\n\"\n",
      " \"plt.ylabel('y')\\n\"\n",
      " \"plt.title('Plot of y = sin(x)')\\n\"\n",
      " 'plt.show()')\n"
     ]
    }
   ],
   "source": [
    "LLM.verbose = True\n",
    "pprint(llm.complete_code(inputs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flask-restful-py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
