{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm import LLM\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"conf.yml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "llm = LLM(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AzureChatOpenAI(client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, temperature=0.0, openai_api_key='9aa144876aa04964b0a823382e7e4878', openai_api_base='https://ail-openai-voc-positive-reviews.openai.azure.com/', openai_proxy='', max_tokens=30, deployment_name='gpt-35-turbo-16k', openai_api_version='2023-05-15', openai_api_type='azure')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompt = \"\"\"\n",
    "I'm working on a programming task/problem and need help filling in the middle of the code. Here's what I have so far:\n",
    "\n",
    "    def post(self):\n",
    "        content_type = request.headers.get('Content-Type')\n",
    "        if (content_type == 'application/json'):\n",
    "            request_json = request.get_json()\n",
    "\n",
    "# Need help filling in the middle here\n",
    "\n",
    "        else:\n",
    "            return \"Content type is not supported.\"\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate.from_template(test_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StrOutputParser()\n",
    "chain = prompt_template | llm.model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_debug\n",
    "\n",
    "# set_debug(True)\n",
    "set_debug(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You're a helpful assistant\"),\n",
    "    HumanMessage(content=\"What is the purpose of model regularization?\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m{\n",
      "  \"lc\": 1,\n",
      "  \"type\": \"constructor\",\n",
      "  \"id\": [\n",
      "    \"langchain_core\",\n",
      "    \"prompt_values\",\n",
      "    \"StringPromptValue\"\n",
      "  ],\n",
      "  \"kwargs\": {\n",
      "    \"text\": \"\\nI'm working on a programming task/problem and need help filling in the middle of the code. Here's what I have so far:\\n\\n    def post(self):\\n        content_type = request.headers.get('Content-Type')\\n        if (content_type == 'application/json'):\\n            request_json = request.get_json()\\n\\n# Need help filling in the middle here\\n\\n        else:\\n            return \\\"Content type is not supported.\\\"\\n\"\n",
      "  }\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 3:llm:AzureChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: \\nI'm working on a programming task/problem and need help filling in the middle of the code. Here's what I have so far:\\n\\n    def post(self):\\n        content_type = request.headers.get('Content-Type')\\n        if (content_type == 'application/json'):\\n            request_json = request.get_json()\\n\\n# Need help filling in the middle here\\n\\n        else:\\n            return \\\"Content type is not supported.\\\"\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 3:llm:AzureChatOpenAI] [1.64s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"To help you fill in the middle of the code, could you please provide more information about what you are trying to achieve or what specific task/problem you\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"length\"\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"ai\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"To help you fill in the middle of the code, could you please provide more information about what you are trying to achieve or what specific task/problem you\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 90,\n",
      "      \"completion_tokens\": 30,\n",
      "      \"total_tokens\": 120\n",
      "    },\n",
      "    \"model_name\": \"gpt-35-turbo-16k\",\n",
      "    \"system_fingerprint\": \"\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 4:parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 4:parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"To help you fill in the middle of the code, could you please provide more information about what you are trying to achieve or what specific task/problem you\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence] [1.65s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"To help you fill in the middle of the code, could you please provide more information about what you are trying to achieve or what specific task/problem you\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'To help you fill in the middle of the code, could you please provide more information about what you are trying to achieve or what specific task/problem you'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flask-restful-py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
